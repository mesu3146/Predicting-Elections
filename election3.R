
election <- read.csv('cleanElectiond.csv', stringsAsFactors = F)

eNames <- read.csv('Enames.csv')
names(election)
eNames

#create 2016 subset for testing
sub16 <- election[,!names(election) %in% c('mfgEmp12', 'DrugFR12','Obese12','Pov12',
                                           'medInc12','incomePercent12','pop12','intMig12','RorD08','mfgEmp12', 'DrugFR08','Obese08','Pov08',
                                           'medInc08','incomePercent08','pop08','intMig08','empQuoMfg12','empQuoTtl2012',
                                           'EmpTtl2012','WageMfg2012','WageTtl2012','County.State','Dem12','Rep08','Rep12','Total08','Total12','emp08','civLab08',
                                           'emp12','domMig08','unemp08','enempR08','percentDem12','unempR08','Dem08','unemp12','domMig12','civLab12',
                                           'netMig12','netMig08','unempR12','popCHG08','popCHG12','percentDem08')]

names(sub16) <- names(eNames)
year <- rep('2016',nrow(sub16))
sub16 <- cbind(sub16,year)

# Convert variables to numeric
sub16[,10:73] <- sapply(sub16[,10:73], as.numeric)
sub16$DrugFR<- sub16[,"DrugFR"]/100
sub16$unempR<- sub16[,"unempR"]/100

## DEALING WITH NAs
  # Option 1: Remove NAs
    # sub16 <- na.omit(sub16)

  # Option 2: Impute NA values with mean
    if (!'imputeR' %in% installed.packages()){
      install.packages('imputeR')
    }
    library(imputeR)
    sub16[sapply(sub16, is.numeric)] = guess(sub16[sapply(sub16, is.numeric)], type='mean')


#2012 subset
sub12 <- election[,!names(election) %in% c('mfgEmp16', 'DrugFR16','Obese16','Pov16',
                                           'medInc16','incomePercent16','pop16','intMig16','RorD16','mfgEmp16', 'DrugFR08','Obese08','Pov08',
                                           'medInc08','incomePercent08','pop08','intMig08','empQuoMfg16','empQuoTtl2016',
                                           'EmpTtl2016','WageMfg2016','WageTtl2016','County.State','Dem16','Rep08','Rep16','Total08','Total16','emp08','civLab08',
                                           'emp16','domMig08','unemp08','enempR08','percentDem16','unempR08','Dem08','unemp16','domMig16','civLab16',
                                           'netMig16','netMig08','unempR16','popCHG08','popCHG16','percentDem08')]


names(sub12) <- names(eNames)
year <- rep('2012',nrow(sub12))
sub12 <- cbind(sub12,year)

# Convert variables to numeric
sub12[,10:73] <- sapply(sub12[,10:73], as.numeric)
sub12$DrugFR<- sub12[,"DrugFR"]/100
sub12$unempR<- sub12[,"unempR"]/100

## DEALING WITH NAs
  # Option 1: Remove NAs
    # sub12 <- na.omit(sub12)

  # Option 2: Impute NA values with mean
    if (!'imputeR' %in% installed.packages()){
    install.packages('imputeR')
    }
    library(imputeR)
    sub12[sapply(sub12, is.numeric)] = guess(sub12[sapply(sub12, is.numeric)], type='mean')


#Test/Validation with even RorD 
#install.packages('caTools')
library(caTools)
help(package = 'caTools')

Y = sub16[,'RorD'] # extract labels from the data
msk = sample.split(Y, SplitRatio=8/10)
table(Y,msk)
t=sum( msk)  # number of elements in one class
f=sum(!msk)  # number of elements in the other class

validation <- sub16[msk,]
test <- sub16[!msk,]

sum(validation$RorD)/nrow(validation)
sum(test$RorD)/nrow(test)

#outcome factor
sub16$outcome <- ifelse(sub16$RorD == 1,'Dem','Rep')
sub16$outcome <- as.factor(sub16$outcome)
sub12$outcome <-ifelse(sub12$RorD ==1,'Dem','Rep')
sub12$outcome <- as.factor(sub12$outcome)
validation$outcome <- ifelse(validation$RorD == 1,'Dem','Rep')
validation$outcome <-as.factor(validation$outcome)
test$outcome <- ifelse(test$RorD == 1,'Dem','Rep')
test$outcome <- as.factor(test$outcome)

#correlation, might want to remove some variables 
cor(subset(sub12,select = -c(fips, county, outcome, RorD,state,year,region)))
names(sub12)
#add population density
sub12$popDens <- sub12$pop/sub12$landArea
sub16$popDens <- sub16$pop/sub16$landArea
validation$popDens <- validation$pop/validation$landArea
test$popDens <- test$pop/test$landArea
  

#normalize data
sub12$popN <- scale(sub12$pop)
sub12$mfgEmpN <- scale(sub12$mfgEmp)
sub12$medIncN <- scale(sub12$medInc)
sub12$intMigN <- scale(sub12$intMig)
sub12$domMigN <- scale(sub12$domMig)
sub12$civLabN <- scale(sub12$civLab)
sub12$EmpTtlN <- scale(sub12$EmpTtl)
sub12$WageMfgN <- scale(sub12$WageMfg)
sub12$WageTtlN <- scale(sub12$WageTtl)
sub12$landAreaN <- scale(sub12$landArea)
sub12$popDensN <- scale(sub12$popDens)
sub12$latitudeN <- scale(sub12$latitude)
sub12$longitudeN <- scale(sub12$longitude)

sub16$popN <- scale(sub16$pop)
sub16$mfgEmpN <- scale(sub16$mfgEmp)
sub16$medIncN <- scale(sub16$medInc)
sub16$intMigN <- scale(sub16$intMig)
sub16$domMigN <- scale(sub16$domMig)
sub16$civLabN <- scale(sub16$civLab)
sub16$EmpTtlN <- scale(sub16$EmpTtl)
sub16$WageMfgN <- scale(sub16$WageMfg)
sub16$WageTtlN <- scale(sub16$WageTtl)
sub16$landAreaN <- scale(sub16$landArea)
sub16$popDensN <- scale(sub16$popDens)
sub16$latitudeN <- scale(sub16$latitude)
sub16$longitudeN <- scale(sub16$longitude)

validation$popN <- scale(validation$pop)
validation$mfgEmpN <- scale(validation$mfgEmp)
validation$medIncN <- scale(validation$medInc)
validation$intMigN <- scale(validation$intMig)
validation$domMigN <- scale(validation$domMig)
validation$civLabN <- scale(validation$civLab)
validation$EmpTtlN <- scale(validation$EmpTtl)
validation$WageMfgN <- scale(validation$WageMfg)
validation$WageTtlN <- scale(validation$WageTtl)
validation$landAreaN <- scale(validation$landArea)
validation$popDensN <- scale(validation$popDens)
validation$latitudeN <- scale(validation$latitude)
validation$longitudeN <- scale(validation$longitude)

test$popN <- scale(test$pop)
test$mfgEmpN <- scale(test$mfgEmp)
test$medIncN <- scale(test$medInc)
test$intMigN <- scale(test$intMig)
test$domMigN <- scale(test$domMig)
test$civLabN <- scale(test$civLab)
test$EmpTtlN <- scale(test$EmpTtl)
test$WageMfgN <- scale(test$WageMfg)
test$WageTtlN <- scale(test$WageTtl)
test$landAreaN <- scale(test$landArea)
test$popDensN <- scale(test$popDens)
test$latitudeN <- scale(test$latitude)
test$longitudeN <- scale(test$longitude)

#PCA
#install.packages('stats')
library(stats)
sub12sub <- subset(sub12,select = c(YdiscussOppose,Ydiscuss,	YCO2limits, YCO2limitsOppose,	YtrustclimsciSST,	YtrustclimsciSSTOppose,
                                     Yregulate,	YregulateOppose,	YsupportRPS,	YsupportRPSOppose,	Yfundrenewables,	YfundrenewablesOppose, Yhappening,
                                     YhappeningOppose,	Yhuman,	YhumanOppose,	Yconsensus,	YconsensusOppose,	Yworried,	YworriedOppose,	Ypersonal,
                                     YpersonalOppose,	YharmUS,	YharmUSOppose,	Ydevharm,	YdevharmOppose,	Yfuturegen,	YfuturegenOppose,
                                     Yharmplants,	YharmplantsOppose,	Ytiming,	YtimingOppose, RorD))

logsub <- log(sub12sub)
logsub$RorD <- sub12sub$RorD

pc.RorD <- sub12sub[,'RorD']
sub12.pca <- prcomp(sub12sub, center = TRUE, scale. = TRUE) 

summary(sub12.pca)

print(sub12.pca)

plot(sub12.pca, type = 'l')
trans$rotation
# library(devtools)
# install_github("ggbiplot", "vqv")
# 
# library(ggbiplot)
# g <- ggbiplot(sub12.pca, obs.scale = 1, var.scale = 1, 
#               groups = pc.RorD, ellipse = TRUE, 
#               circle = TRUE)
# g <- g + scale_color_discrete(name = '')
# g <- g + theme(legend.direction = 'horizontal', 
#                legend.position = 'top')
# print(g)

#install.packages('caret')
#install.packages('e1071')
require(caret)
require(e1071)
trans = preProcess(subset(logsub, select = -RorD), 
                   method=c("BoxCox", "center", 
                            "scale", "pca"))
PC = predict(trans,subset(logsub, select = -RorD))
summary(PC)
names(PC)

#random forest
library(randomForest)
set.seed(300)
forest.vote = randomForest(outcome~  pop + mfgEmp + medInc + intMig + domMig + civLab + EmpTtl + WageMfg + WageTtl + 
                             landArea + popDens + latitude + longitude + Ydiscuss + YCO2limits + Yfundrenewables +Yhappening +
                           Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                          YharmUS,data=sub12)

pred.forest = predict(forest.vote)
table(sub12$outcome,pred.forest)


#predict 2016 forest
pred.forest16 <- predict(forest.vote,validation,type ='response')
#2016 outcomes vs. predict
table(validation$outcome,pred.forest16)
forest16 <- table(validation$outcome,pred.forest16)

#Accuracy
(forest16[1] + forest16[4])/(forest16[1]+forest16[2]+forest16[3] + forest16[4])

#boosting
library(gbm)
set.seed(300)

boost.vote <- gbm(RorD~  mfgEmp + medInc + intMig + domMig + civLab + EmpTtl + WageMfg + WageTtl + 
                    landArea + popDens + latitude + longitude + Ydiscuss + YCO2limits + Yfundrenewables +Yhappening +
                    Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                    YharmUS, data=sub12, distribution = "bernoulli", n.trees=1000)

pred.vote <- predict(boost.vote,n.trees=1000,type="response")
pred.vote <- round(pred.vote,0)
table(sub12$RorD, pred.vote)
summary(boost.vote)
#predict 2016 boosting
pred.vote16 <- predict(boost.vote,validation,n.trees=1000,type="response")
pred.vote16 <- round(pred.vote16,0)
vote16 <- table(validation$RorD,pred.vote16)

#accuracy
(vote16[1] + vote16[4]) / (vote16[1] + vote16[2] + vote16[3] + vote16[4])

#majority class proportion 2016
1- sum(validation$RorD)/nrow(validation)
1- sum(sub12$RorD)/nrow(sub12)

#boosting 2: probability (for votes by state) 
library(gbm)
set.seed(300)


boost.vote2 <- gbm(RorD~ mfgEmp + medInc + intMig + domMig + civLab + EmpTtl + WageMfg + WageTtl + 
                     landArea + popDens + latitude + longitude + Ydiscuss + YCO2limits + Yfundrenewables +Yhappening +
                     Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                     YharmUS,data=sub12,distribution = "bernoulli",n.trees=1000)

pred.vote2 <- predict(boost.vote2,n.trees=1000,type="response")
table(sub12$RorD,pred.vote2)
summary(boost.vote2)

#sub16 for ROC
CUTOFF <- .4
pred.voteRR <- as.integer(predict(boost.vote2,sub16, n.trees=1000,type="response")>CUTOFF)

table(sub16$RorD,pred.voteRR)
vote16 <-  table(sub16$RorD,pred.voteRR)
(vote16[1] + vote16[4]) / (vote16[1] + vote16[2] + vote16[3] + vote16[4])

#predict 2016 boosting (for votes by state)
pred.vote16.2 <- predict(boost.vote2,sub16,n.trees=1000,type="response")
vote16.2 <- table(sub16$RorD,pred.vote16.2)
sub16v <-cbind(sub16,pred.vote16.2)

pred <- as.integer(pred.vote16.2 > .5)
conf.16 <- table(sub16$RorD, pred)
(conf.16[1] + conf.16[4])/(conf.16[1]+conf.16[2]+conf.16[3]+conf.16[4])

#for random forest..
forest16prob <- predict(forest.vote,sub16,type ='prob')
forest16prob2 <- as.vector(forest16prob[,1])
predForest <- round(forest16prob,0)
preForestV <- as.vector(predForest[,1])
conff.16 <- table(sub16$RorD, preForestV)
(conff.16[1] + conff.16[4])/(conff.16[1]+conff.16[2]+conff.16[3]+conff.16[4])

# we can't use total votes because technically we shouldnt' know total votes. determine % of pop voted in 2008, 2012..
election[,8:116] <- sapply(election[8:116], as.numeric)
election$pct2008 <- election$Total08/election$pop08
election$pct2012 <- election$Total12/election$pop12
election$avgVote <- rowMeans(subset(election, select = c(pct2008, pct2012)), na.rm = TRUE)
election$vote2016 <- round(election$pop16 * election$avgVote,0)
(election$Total16 - election$vote2016)/election$Total16

sub16v <- merge(sub16v,election[,c('fips','vote2016')], by = c('fips'))
head(sub16v)
#votes per county

#for boosted
sub16v$Dvote <- round(sub16v$vote2016*pred.vote16.2,0)
sub16v$Rvote <- sub16v$vote2016 - sub16v$Dvote

#for forest
sub16v$Dvote <- round(sub16v$vote2016*forest16prob2,0)
sub16v$Rvote <- sub16v$vote2016- sub16v$Dvote
#aggregate votes by state
library("data.table")
sub16v <- as.data.table(sub16v)
setkey(sub16v,state)
sub16A <- sub16v[,list(republicanP = sum(Rvote, na.rm = TRUE),republicanA = sum(rep, na.rm = TRUE),
                       democratP = sum(Dvote, na.rm = TRUE), democratA = sum(dem, na.rm = TRUE), Obese = mean(Obese), DrugFR = mean(DrugFR), mfgEmp = mean(mfgEmp)
                       ,Pov = mean(Pov), popDens = mean(popDens), intMig = mean(intMig), civLab = mean(civLab), Ydiscuss = mean(Ydiscuss), 
                       YCO2limits = mean(YCO2limits), Yfundrenewables = mean(Yfundrenewables), Yhappening = mean(Yhappening), Yhuman = mean(Yhuman), 
                       YharmplantsOppose = mean(YharmplantsOppose), Ytiming = mean(Ytiming), Yconsensus = mean(Yconsensus), Yworried = mean(Yworried)), by = 'state']

#if rep votes > than dem votes, 0 else 1
sub16A$RorDp <- ifelse(sub16A$republicanP > sub16A$democratP, 0 ,1)  
sub16A$RorDa <- ifelse(sub16A$republicanA > sub16A$democratA, 0 ,1)  

#predicted democratic states
sum(sub16A$RorDp)
#actual democratic states
sum(sub16A$RorDa)
#incorrect states
error16 <- sub16A[sub16A$RorDa != sub16A$RorDp,]
error16[,c('state','RorDp','RorDa')]
tail(sub16A)


electoralVotes <- read.csv('electoralVotes.csv')

electoralVotes <- electoralVotes[order(electoralVotes$stateAb),]
sub16A <- cbind(sub16A,electoralVotes$EV)

#election2016 <- write.csv(sub16A, file = '2016election.csv')

#actual vs. predicted electoral votes
sub16A$actualDemEVs <- sub16A$RorDa*sub16A$V2
sub16A$predictedDemEVs <- sub16A$RorDp*sub16A$V2
sub16A$actualRepEVs <-  sub16A$V2 - sub16A$actualDemEVs
sub16A$predictedRepEVs <- sub16A$V2 - sub16A$predictedDemEVs

##these are off by about 20? 
sum(sub16A$actualDemEVs)
sum(sub16A$actualRepEVs)

sum(sub16A$predictedDemEVs)
sum(sub16A$predictedRepEVs)


#regression

#first:
sub12$outcomebinomial <- NA
for (i in 1:length(sub12)) {
	if (sub12$outcome[i] == "Rep") {
		sub12$outcomebinomial[i] <- 1
	} else {
		sub12$outcomebinomial[i] <- 0
	}
}

logit.vote = glm(outcomebinomial~  pop + mfgEmp + medInc + intMig + domMig + civLab + EmpTtl + WageMfg + WageTtl + 
                             landArea + popDens + latitude + longitude 
                             + Ydiscuss + YCO2limits + Yfundrenewables +Yhappening + Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                             YharmUS, data=sub12, family=binomial)
summary(logit.vote)
#second:
logit.vote2 = glm(outcomebinomial~  mfgEmp + domMig + WageMfg + WageTtl + 
                             landArea + popDens + longitude + Ydiscuss + YCO2limits + Yfundrenewables) 							+ Yhuman  + Yconsensus +	Yworried+	Ypersonal ,data=sub12t, family=binomial)
summary(logit.vote2)

test$outcomebinomial <- NA
for (i in 1:length(test)) {
	if (test$outcome[i] == "Rep") {
		test$outcomebinomial[i] <- 1
	} else {
		test$outcomebinomial[i] <- 0
	}
}
pred.logit2 <- predict(logit.vote2, newdata=test, type="response")
fitted.results2 <- ifelse(pred.logit2 > 0.5, 1, 0)
misClassError2 <- mean(fitted.results2 != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError2))

#Logistic Regression Model 3

logit.vote3 = glm(outcomebinomial~  WageTtl + 
                             popDens + longitude + YCO2limits + Yhuman  + Yconsensus +	Ypersonal ,data=sub12, family=binomial)
summary(logit.vote3)
pred.logit3 <- predict(logit.vote3, newdata=test, type="response")
fitted.results3 <- ifelse(pred.logit3 > 0.5, 1, 0)
misClassError3 <- mean(fitted.results3 != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError3))

#Logistic 4:

logit.vote4 = glm(outcomebinomial~  DrugFR+Obese+Pov+medInc+incomePercent+pop+civLab+emp+unempR+
			college+pctBlack+pctAsian+pctHispanic+pctWhite+pctForeign+WageMfg+popDens+landArea+
			 + Ydiscuss + YCO2limits + Yfundrenewables + Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                          YharmUS, data=sub12, family=binomial)
summary(logit.vote4)
pred.logit4 <- predict(logit.vote4, newdata=test, type="response")
fitted.results4 <- ifelse(pred.logit4 > 0.5, 1, 0)
misClassError4 <- mean(fitted.results4 != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError4))

# temp forest:
set.seed(300)
forest.vote4 = randomForest(outcome~  DrugFR+Obese+Pov+medInc+incomePercent+pop+civLab+emp+unempR+
			college+pctBlack+pctAsian+pctHispanic+pctWhite+pctForeign+WageMfg+popDens+landArea+
			 + Ydiscuss + YCO2limits + Yfundrenewables + Yhuman +	YharmplantsOppose + Ytiming + Yconsensus + 
			 Yworried + Ypersonal + YharmUS ,data=sub12)
summary(forest.vote4)
importance(forest.vote4)
pred.forest4=predict(forest.vote4)
table(sub12t$outcome, pred.forest4)
#accuracy:
(706+2137)/(706+2137+179+109)
# Testing on the test set:
test$pred.forest4 <- predict(forest.vote4, newdata=test, type="response")
test$forestoutcome <- NA
for (i in 1:length(test)) {
	if (test$pred.forest4[i] == 'Rep') {
		test$forestoutcome[i] <- 1
	} else {
		test$forestoutcome[i] <- 0
	}
}


fitted.results4f <- ifelse(test$forestoutcome > 0.5, 1, 0)
misClassError4f <- mean(fitted.results4f != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError4f))

# NEURAL NET
library(neuralnet)
# train the neural network
set.seed(300)
vote.net <- neuralnet(RorD~  popN + mfgEmpN + medIncN + intMigN + domMigN + civLabN + EmpTtlN + WageMfgN + WageTtlN + 
                        landAreaN + popDensN + latitudeN + longitudeN + Ydiscuss + YCO2limits + Yfundrenewables +Yhappening +
                        Yhuman + YharmplantsOppose + Ytiming + Yconsensus + Yworried + Ypersonal +
                        YharmUS, data=test, hidden=c(4,3,2))
plot(vote.net)
vote.net 


#first:
sub12t$outcomebinomial <- NA
for (i in 1:length(sub12t)) {
	if (sub12t$outcome[i] == "Rep") {
		sub12t$outcomebinomial[i] <- 1
	} else {
		sub12t$outcomebinomial[i] <- 0
	}
}

logit.vote = glm(outcomebinomial~  pop + mfgEmp + medInc + intMig + domMig + civLab + EmpTtl + WageMfg + WageTtl + 
                             landArea + popDens + latitude + longitude 
                             + Ydiscuss + YCO2limits + Yfundrenewables +Yhappening + Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                          YharmUS,data=sub12t, family=binomial)
summary(logit.vote)
#second:
logit.vote2 = glm(outcomebinomial~  mfgEmp + domMig + WageMfg + WageTtl + 
                             landArea + popDens + longitude + Ydiscuss + YCO2limits + Yfundrenewables 							+ Yhuman  + Yconsensus +	Yworried+	Ypersonal ,data=sub12t, family=binomial)
summary(logit.vote2)

test$outcomebinomial <- NA
for (i in 1:length(test)) {
	if (test$outcome[i] == "Rep") {
		test$outcomebinomial[i] <- 1
	} else {
		test$outcomebinomial[i] <- 0
	}
}
pred.logit2 <- predict(logit.vote2, newdata=test, type="response")
fitted.results2 <- ifelse(pred.logit2 > 0.5, 1, 0)
misClassError2 <- mean(fitted.results2 != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError2))

#Logistic Regression Model 3

logit.vote3 = glm(outcomebinomial~  WageTtl + 
                             popDens + longitude + YCO2limits + Yhuman  + Yconsensus +	Ypersonal ,data=sub12t, family=binomial)
summary(logit.vote3)
pred.logit3 <- predict(logit.vote3, newdata=test, type="response")
fitted.results3 <- ifelse(pred.logit3 > 0.5, 1, 0)
misClassError3 <- mean(fitted.results3 != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError3))

#Logistic 4:

logit.vote4 = glm(outcomebinomial~  DrugFR+Obese+Pov+medInc+incomePercent+pop+civLab+emp+unempR+
			college+pctBlack+pctAsian+pctHispanic+pctWhite+pctForeign+WageMfg+popDens+landArea+
			 + Ydiscuss + YCO2limits + Yfundrenewables + Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                          YharmUS ,data=sub12t, family=binomial)
summary(logit.vote4)
pred.logit4 <- predict(logit.vote4, newdata=test, type="response")
fitted.results4 <- ifelse(pred.logit4 > 0.5, 1, 0)
misClassError4 <- mean(fitted.results4 != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError4))

# temp forest:
set.seed(300)
forest.vote4 = randomForest(outcome~  DrugFR+Obese+Pov+medInc+incomePercent+pop+civLab+emp+unempR+
			college+pctBlack+pctAsian+pctHispanic+pctWhite+pctForeign+WageMfg+popDens+landArea+
			 + Ydiscuss + YCO2limits + Yfundrenewables + Yhuman +	YharmplantsOppose + Ytiming + Yconsensus +	Yworried+	Ypersonal +
                          YharmUS ,data=sub12t)
summary(forest.vote4)
importance(forest.vote4)
pred.forest4=predict(forest.vote4)
table(sub12t$outcome, pred.forest4)
#accuracy:
(706+2137)/(706+2137+179+109)
# Testing on the test set:
test$pred.forest4 <- predict(forest.vote4, newdata=test, type="response")
test$forestoutcome <- NA
for (i in 1:length(test)) {
	if (test$pred.forest4[i] == 'Rep') {
		test$forestoutcome[i] <- 1
	} else {
		test$forestoutcome[i] <- 0
	}
}


fitted.results4f <- ifelse(test$forestoutcome > 0.5, 1, 0)
misClassError4f <- mean(fitted.results4f != test$outcomebinomial, na.rm=TRUE)
print(paste('Accuracy',1-misClassError4f))


#ROC curve and AUC calcs 

#install.packages('pROC')
library(pROC)
#forest.vote / pred.forest16 (CUTOFF = .5) (accuracy = .95 )  AUCsub16 = .897
#forest.vote / pred.forest16 (CUTOFF = .3) (accuracy = .88 )  AUCsub16 = .913
#boost.vote / pred.voteR (CUTOFF = .5) (accuracy = .936) AUCsub16 = .91084
#boost.vote / pred.voteR (CUTOFF = .42) (accuracy = .9 )  AUCsub16 = .924
#boost.vote2 / pred.voteRR (CUTOFF = .5) (accuracy = .9)  AUCsub16 = .901
#boost.vote2 / pred.voteRR (CUTOFF = .4) (accuracy = .867)  AUCsub16 = .892

roc_obj <- roc(sub16$RorD, pred.voteR) ## change these values for each model
auc(roc_obj)

roc_df <- data.frame(
  TPR=rev(roc_obj$sensitivities), 
  FPR=rev(1 - roc_obj$specificities))

rectangle <- function(x, y, width, height, density=12, angle=-45, ...)
  polygon(c(x,x,x+width,x+width), c(y,y+height,y+height,y), 
          density=density, angle=angle, ...)

roc_df <- transform(roc_df, 
                    dFPR = c(diff(FPR), 0),
                    dTPR = c(diff(TPR), 0))

plot(0:10/10, 0:10/10, type='n', xlab="FPR", ylab="TPR")
abline(h=0:10/10, col="lightblue")
abline(v=0:10/10, col="lightblue")

with(roc_df, {
  mapply(rectangle, x=FPR, y=0,   
         width=dFPR, height=TPR, col="green", lwd=2)
  mapply(rectangle, x=FPR, y=TPR, 
         width=dFPR, height=dTPR, col="blue", lwd=2)
  
  lines(FPR, TPR, type='b', lwd=3, col="red")
})



simple_auc <- function(TPR, FPR){
  # inputs already sorted, best scores first 
  dFPR <- c(diff(FPR), 0)
  dTPR <- c(diff(TPR), 0)
  sum(TPR * dFPR) + sum(dTPR * dFPR)/2
}

with(roc_df, simple_auc(TPR, FPR))

#AUC
rank_comparison_auc <- function(labels, scores, plot_image=TRUE, ...){
  score_order <- order(scores, decreasing=TRUE)
  labels <- as.logical(labels[score_order])
  scores <- scores[score_order]
  pos_scores <- scores[labels]
  neg_scores <- scores[!labels]
  n_pos <- sum(labels)
  n_neg <- sum(!labels)
  M <- outer(sum(labels):1, 1:sum(!labels), 
             function(i, j) (1 + sign(pos_scores[i] - neg_scores[j]))/2)
  
  AUC <- mean (M)
  if (plot_image){
    image(t(M[nrow(M):1,]), ...)
    library(pROC)
    with( roc(labels, scores),
          lines((1 + 1/n_neg)*((1 - specificities) - 0.5/n_neg), 
                (1 + 1/n_pos)*sensitivities - 0.5/n_pos, 
                col="blue", lwd=2, type='b'))
    text(0.5, 0.5, sprintf("AUC = %0.4f", AUC))
  }
  
  return(AUC)
}
rank_comparison_auc(labels=as.logical(sub16$RorD), scores=pred.voteR) ## change these values for each model 


##KNN
# remove all the missing values
sub12.omit=na.omit(sub12)
sub16.omit=na.omit(sub16)

# remove all the non-numeric columns
sub12.omit$county<-NULL
sub12.omit$state<-NULL
sub12.omit$region<-NULL
sub12.omit$year<-NULL
sub16.omit$state<-NULL
sub16.omit$county<-NULL
sub16.omit$region<-NULL
sub16.omit$year<-NULL

# rename columns
elec.train = sub12.omit
elec.test = sub16.omit

#x<-NA
#for(i in 1:length(elec.train)) {
#x[i]<-sum(is.na(elec.train[i]))
#  }
#x
#sum(sapply(elec.test,is.numeric))

# find k value which maximize accuracy
vk = seq(1,51,2)
accuracy = vk
for (i in 1:length(vk)){
  election.knn = knn(scale(elec.train[,sapply(elec.train,is.numeric)]),scale(elec.test[,sapply(elec.test,is.numeric)]),elec.train$outcome,k=vk[i])
  accuracy[i] = mean(elec.test$outcome==election.knn)  
}
plot(vk,accuracy,xlab='k',ylab='test accuracy',col='blue')
accuracy
max(accuracy)
# k=37

# knn function
election.knn = knn(scale(elec.train[,sapply(elec.train,is.numeric)]),scale(elec.test[,sapply(elec.test,is.numeric)]),elec.train$outcome,k=37)
election.knn
table(elec.test$outcome,election.knn)
##accuracy
(480+2426)/(480+9+201+2426)
##93.26%
